{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e72_J3Siyz_n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Input\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data from the Excel file\n",
        "arabic_data = pd.read_excel('/content/6000.xlsx')\n",
        "\n",
        "# Now, you can work with the 'arabic_data' DataFrame.\n"
      ],
      "metadata": {
        "id": "xxlmlhijD0yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Load the data from the Excel file\n",
        "arabic_data = pd.read_excel('/content/6000.xlsx')\n",
        "\n",
        "# Define normalization functions\n",
        "def normalize_arabic(text):\n",
        "    # Your normalization code here\n",
        "    return text\n",
        "\n",
        "def deNoise(text):\n",
        "    # Your denoising code here\n",
        "    return text\n",
        "\n",
        "# Remove punctuations\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    return text.translate(translator)\n",
        "\n",
        "# Apply preprocessing to the 'text' column\n",
        "arabic_data['text'] = arabic_data['text'].apply(normalize_arabic)\n",
        "arabic_data['text'] = arabic_data['text'].apply(deNoise)\n",
        "arabic_data['text'] = arabic_data['text'].apply(remove_punctuation)\n",
        "\n",
        "# Remove rows with null values\n",
        "arabic_data.dropna(axis=0, thresh=None, subset=None, inplace=True)\n"
      ],
      "metadata": {
        "id": "-RcTJvHDzCFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the column names in your DataFrame\n",
        "print(arabic_data.columns)\n",
        "\n",
        "# Verify the structure of your loaded data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjA5gRJatoSo",
        "outputId": "f17fe3fb-6ef9-459f-db16-5495f5314f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Sentences', 'Class'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import ISRIStemmer\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define a function for text cleaning\n",
        "def clean_text(text):\n",
        "    # Check for NaN values\n",
        "    if pd.isna(text):\n",
        "        return ''  # Handle missing values by returning an empty string\n",
        "    # Remove HTML tags using BeautifulSoup\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "    return text\n",
        "\n",
        "# Apply the text cleaning function to your text data, handling missing values\n",
        "arabic_data['Sentences'] = arabic_data['Sentences'].apply(clean_text)\n",
        "\n",
        "# Initialize the ISRIStemmer\n",
        "stemmer = ISRIStemmer()\n",
        "\n",
        "# Define a function for stemming\n",
        "def stem_text(text):\n",
        "    words = text.split()\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "    return ' '.join(stemmed_words)\n",
        "\n",
        "# Apply stemming to your text data\n",
        "arabic_data['Sentences'] = arabic_data['Sentences'].apply(stem_text)\n",
        "\n",
        "# Define a function to remove stop words\n",
        "def remove_stopwords(text, stop_words):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Get the set of Arabic stop words\n",
        "stop_words_arabic = set(stopwords.words(\"arabic\"))\n",
        "\n",
        "# Apply stop word removal to your text data\n",
        "arabic_data['Sentences'] = arabic_data['Sentences'].apply(lambda x: remove_stopwords(x, stop_words_arabic))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G6d8dAUuGcn",
        "outputId": "66f86016-3997-4ce6-c20d-ff7d9955e7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-13-2c38cf784134>:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = set(labels)\n",
        "print(unique_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIn3bvyivrMr",
        "outputId": "4dcdd697-64d6-49a3-ea88-5a02de1e46ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Ellipsis, 'class2', 'class1', 'class3'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in labels:\n",
        "    print(type(label))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwDdEZjuvxZj",
        "outputId": "6026ff6a-3432-4d99-b056-531772eb71eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'ellipsis'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "value_counts = Counter(labels)\n",
        "print(value_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4IoDnBNvy7e",
        "outputId": "b5b32bf9-b6a8-46e5-c3e0-b499e8cbed17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'class1': 2, 'class2': 1, 'class3': 1, Ellipsis: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in labels:\n",
        "    print(label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKocBuI-v2Rj",
        "outputId": "0c402cd7-4e45-48b3-dec2-7342c5362e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class1\n",
            "class2\n",
            "class1\n",
            "class3\n",
            "Ellipsis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original labels\n",
        "labels = ['class1', 'class2', 'class1', 'class3', 'Ellipsis']\n",
        "\n",
        "# Cleaned labels (remove 'Ellipsis' and ensure uniform data type)\n",
        "cleaned_labels = [label for label in labels if label != 'Ellipsis']\n",
        "\n",
        "# Check the cleaned labels\n",
        "print(cleaned_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hq7si6PwE8J",
        "outputId": "6344aa91-3ecd-44c0-cdf4-8479bff5aa51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['class1', 'class2', 'class1', 'class3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n"
      ],
      "metadata": {
        "id": "62KOjS-YvOiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first few rows of the dataset including labels\n",
        "print(arabic_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBAXmHqb8qpL",
        "outputId": "8febce3d-c8ac-4271-c20e-f364196ca9c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Sentences  Class\n",
            "0  لدي قرح جلس نوب قدم صوت قان حدد مدة عمل حكم زر...      0\n",
            "1  خدم قدم حكم يفء رسوم؟؟ وفر حمم نظف نقط حدودية؟...      0\n",
            "2                               فرض ضرب دلل فكر قرر.      0\n",
            "3                   ان نسر الى امم نجد رغب اعت الى .      0\n",
            "4  عدد سئل الة تم عدل حكم وكأ حكم سبق كانت صرف اي...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the labels\n",
        "print('[+] Sample labels:', labels[:10])\n",
        "\n",
        "# Check the number of unique labels before label encoding\n",
        "print('[+] Number of unique labels before encoding:', len(set(labels)))\n",
        "\n",
        "# Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Check the number of unique labels after label encoding\n",
        "print('[+] Number of unique labels after encoding:', len(set(encoded_labels)))\n",
        "\n",
        "# Print a few encoded labels to verify\n",
        "print('[+] Encoded labels:', encoded_labels[:10])\n",
        "\n",
        "# Continue with one-hot encoding\n",
        "labels = to_categorical(encoded_labels)\n",
        "print(labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nHmRZNG8XbQ",
        "outputId": "2486b813-0344-48ba-a499-36e43c626383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Sample labels: ['class1', 'class2', 'class1', 'class3', 'Ellipsis']\n",
            "[+] Number of unique labels before encoding: 4\n",
            "[+] Number of unique labels after encoding: 4\n",
            "[+] Encoded labels: [1 2 1 3 0]\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "iZhNY-9u-cYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "eiN2Ysr9-dhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text data\n",
        "texts = [\n",
        "    \"This is the first sentence.\",\n",
        "    \"Here is the second sentence.\",\n",
        "    \"And this is the third sentence.\"\n",
        "]\n",
        "\n",
        "# Rest of your code for tokenization and label encoding\n"
      ],
      "metadata": {
        "id": "hmKryjDWwn93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Sample text data (replace with your actual text data)\n",
        "texts = [\n",
        "    \"This is the first sentence.\",\n",
        "    \"Here is the second sentence.\",\n",
        "    \"And this is the third sentence.\"\n",
        "]\n",
        "\n",
        "# Sample labels (replace with your actual labels)\n",
        "labels = ['class1', 'class2', 'class1']\n",
        "\n",
        "# Tokenization\n",
        "print('[+] Tokenization')\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "word_index = tokenizer.word_index\n",
        "print('[+] The number of unique tokens:', len(word_index))\n",
        "data = pad_sequences(sequences, maxlen=10)\n",
        "\n",
        "# Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Print encoded labels\n",
        "print('[+] Encoded labels:', labels_encoded)\n",
        "\n",
        "# Now, 'data' contains your tokenized text data, and 'labels_encoded' contains your encoded class labels.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCWaUs-zwxQX",
        "outputId": "1d3aa16f-fe52-4c1b-8519-0b1e08e196bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Tokenization\n",
            "[+] The number of unique tokens: 9\n",
            "[+] Encoded labels: [0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "from array import array\n",
        "from keras import backend as k\n",
        "import tensorflow as tf\n",
        "import gc\n",
        "\n",
        "batch_sizes = [1000, 250, 500, 100]\n",
        "epochs_values = [10, 15, 20, 30, 40, 50, 60]\n",
        "optimizer_values = [\"rmsprop\", \"adam\", \"Adadelta\"]\n",
        "\n",
        "def create_model():\n",
        "    sequence_input = Input(shape=(SEQ_LEN,), dtype='int32')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "    l_covl = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "    l_pooll = MaxPooling1D(5)(l_covl)\n",
        "    l_cov2 = Conv1D(128, 5, activation='relu')\n",
        "    l_pool2 = MaxPooling1D(5)(l_cov2)\n",
        "    l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
        "    l_pool3 = MaxPooling1D(35)(l_cov3)\n",
        "    l_flat = Flatten()(l_pool3)\n",
        "    l_dense = Dense(len(macronum), activation=\"relu\")(l_flat)\n",
        "    preds = Dense(len(macronum), activation='softmax')(l_dense)\n",
        "    model = Model(sequence_input, preds)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "4Q3P7ds6zW0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "73zZLax6xaCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sequence length (replace with the actual sequence length you're using)\n",
        "SEQ_LEN = 100\n"
      ],
      "metadata": {
        "id": "4XA-cxV_xJ6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your create_model function\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add layers to your CNN model\n",
        "    # ...\n",
        "\n",
        "    # Build the model\n",
        "    model.build(input_shape=(None, SEQ_LEN))  # Replace SEQ_LEN with your actual sequence length\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "P8rLkLZfxa39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Arabic text data\n",
        "arabic_texts = [\n",
        "    \"السلام عليكم ورحمة الله وبركاته\",\n",
        "    \"هذا مثال على نص عربي للتصنيف\",\n",
        "    \"اللغة العربية جميلة\",\n",
        "    # Add more Arabic text samples here\n",
        "]\n"
      ],
      "metadata": {
        "id": "7xTnKYcl0k7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example data\n",
        "data = pd.DataFrame({'text': ['Arabic text 1', 'Arabic text 2', 'Arabic text 3'],\n",
        "                     'label': ['class1', 'class2', 'class1']})\n",
        "\n",
        "# Extract x and y\n",
        "x = data['text']\n",
        "y = data['label']\n"
      ],
      "metadata": {
        "id": "5__yDRXH1b-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split your dataset into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into 80% training and 20% validation\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now, you can use x_train, y_train, x_val, and y_val in your model.fit() function\n"
      ],
      "metadata": {
        "id": "cz-ITv1-1Fsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder\n"
      ],
      "metadata": {
        "id": "B2MQpVYw2JDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)  # 'texts' is a list of strings\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n"
      ],
      "metadata": {
        "id": "E6Q8alU94UOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_sequence_length = 100  # Set the desired sequence length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n"
      ],
      "metadata": {
        "id": "BdyVUVIS4Xu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "integer_labels = label_encoder.fit_transform(labels)\n"
      ],
      "metadata": {
        "id": "Dxu0we2R4Yug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(padded_sequences, integer_labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "D54u8uUZ4c_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(x_train))\n",
        "print(type(x_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dCD7U8K4wFk",
        "outputId": "ef5df692-9751-4d10-97f1-2284353a51b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(y_train))\n",
        "print(type(y_val))\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHhteh1d4x9W",
        "outputId": "c9dc79af-fb0d-4958-f682-d410e55b346b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(2,)\n",
            "(1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expected_shape = (SEQ_LEN,)  # Replace with the actual sequence length\n",
        "input_shape = x_train.shape[1:]  # Assuming the first dimension is the batch size\n",
        "print(\"Expected Input Shape:\", expected_shape)\n",
        "print(\"Actual Input Shape:\", input_shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KPLSGRs42Y-",
        "outputId": "78582de7-5c65-4761-d895-1dda5d9d93de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected Input Shape: (100,)\n",
            "Actual Input Shape: (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 10000  # Adjust this based on your vocabulary size\n",
        "EMBEDDING_DIM = 100  # Adjust this based on your embedding dimension\n",
        "NUM_CLASSES = 10     # Adjust this based on the number of classes in your classification task\n"
      ],
      "metadata": {
        "id": "Cu35RiK38r91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert integer labels to one-hot encoded labels\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_val = to_categorical(y_val, num_classes=10)\n"
      ],
      "metadata": {
        "id": "l9efCIrd9Wpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.compat.v1.keras.optimizers import SGD as LegacySGD\n",
        "\n",
        "# Define your hyperparameter values\n",
        "epochs_values = [10, 20, 30]\n",
        "batch_sizes = [32, 64, 128]\n",
        "optimizer_values = [LegacySGD(learning_rate=0.01), Adam(learning_rate=0.001)]\n",
        "\n",
        "# ... (the rest of your code remains the same)\n"
      ],
      "metadata": {
        "id": "FOfsBQXc93p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Input\n"
      ],
      "metadata": {
        "id": "eUmczbUG-sId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD  # Use legacy optimizer\n",
        "\n",
        "# Define your hyperparameter values\n",
        "epochs_values = [10, 20, 30]\n",
        "batch_sizes = [32, 64, 128]\n",
        "\n",
        "# Determine the sequence length (SEQ_LEN) based on your data\n",
        "SEQ_LEN = 100  # Set the appropriate value based on your data\n",
        "\n",
        "# Define your create_model function with the correct input shape\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    # Modify the input shape based on your data\n",
        "    model.add(Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=SEQ_LEN))\n",
        "    model.add(Conv1D(128, 5, activation='relu'))\n",
        "    model.add(MaxPooling1D(5))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "# Training loop\n",
        "for i in epochs_values:\n",
        "    for x in batch_sizes:\n",
        "        # Create and compile the model\n",
        "        model = create_model()\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "        # Print model summary\n",
        "        model.summary()\n",
        "\n",
        "        print(\"------------------\")\n",
        "        print(\"Epochs: {0} - Batch Size: {1}\".format(i, x))\n",
        "        print(\"--------------------------\")\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=i, batch_size=x)\n",
        "\n",
        "        print(\">>>END<<<\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGS1lqrtCZIq",
        "outputId": "5a604ebe-e4d8-425d-f92f-b0b093d6c1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_21 (Embedding)    (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d_21 (Conv1D)          (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " max_pooling1d_21 (MaxPooli  (None, 19, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " flatten_21 (Flatten)        (None, 2432)              0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 128)               311424    \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1376842 (5.25 MB)\n",
            "Trainable params: 1376842 (5.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------\n",
            "Epochs: 10 - Batch Size: 32\n",
            "--------------------------\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 2.2984 - accuracy: 0.5000 - val_loss: 2.3258 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2812 - accuracy: 0.5000 - val_loss: 2.3108 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.2662 - accuracy: 0.5000 - val_loss: 2.2960 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.2513 - accuracy: 0.5000 - val_loss: 2.2822 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.2367 - accuracy: 0.5000 - val_loss: 2.2685 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2220 - accuracy: 0.5000 - val_loss: 2.2563 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2080 - accuracy: 0.5000 - val_loss: 2.2440 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1942 - accuracy: 0.5000 - val_loss: 2.2314 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.1802 - accuracy: 0.5000 - val_loss: 2.2189 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.1661 - accuracy: 0.5000 - val_loss: 2.2062 - val_accuracy: 0.0000e+00\n",
            ">>>END<<<\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_22 (Embedding)    (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d_22 (Conv1D)          (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " max_pooling1d_22 (MaxPooli  (None, 19, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " flatten_22 (Flatten)        (None, 2432)              0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 128)               311424    \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1376842 (5.25 MB)\n",
            "Trainable params: 1376842 (5.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------\n",
            "Epochs: 10 - Batch Size: 64\n",
            "--------------------------\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 2.3320 - accuracy: 0.0000e+00 - val_loss: 2.2862 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.3121 - accuracy: 0.0000e+00 - val_loss: 2.2716 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2936 - accuracy: 0.0000e+00 - val_loss: 2.2569 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2759 - accuracy: 0.5000 - val_loss: 2.2429 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2601 - accuracy: 0.5000 - val_loss: 2.2313 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2449 - accuracy: 0.5000 - val_loss: 2.2201 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2312 - accuracy: 0.5000 - val_loss: 2.2088 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2189 - accuracy: 0.5000 - val_loss: 2.1993 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.2070 - accuracy: 0.5000 - val_loss: 2.1885 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.1952 - accuracy: 0.5000 - val_loss: 2.1774 - val_accuracy: 1.0000\n",
            ">>>END<<<\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_23 (Embedding)    (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d_23 (Conv1D)          (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " max_pooling1d_23 (MaxPooli  (None, 19, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " flatten_23 (Flatten)        (None, 2432)              0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 128)               311424    \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1376842 (5.25 MB)\n",
            "Trainable params: 1376842 (5.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------\n",
            "Epochs: 10 - Batch Size: 128\n",
            "--------------------------\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.3020 - accuracy: 0.0000e+00 - val_loss: 2.3114 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2809 - accuracy: 0.5000 - val_loss: 2.2918 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.2622 - accuracy: 0.5000 - val_loss: 2.2749 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.2469 - accuracy: 0.5000 - val_loss: 2.2610 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2326 - accuracy: 0.5000 - val_loss: 2.2480 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2195 - accuracy: 0.5000 - val_loss: 2.2350 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2072 - accuracy: 0.5000 - val_loss: 2.2222 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 2.1949 - accuracy: 0.5000 - val_loss: 2.2086 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.1819 - accuracy: 0.5000 - val_loss: 2.1951 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.1684 - accuracy: 0.5000 - val_loss: 2.1800 - val_accuracy: 0.0000e+00\n",
            ">>>END<<<\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_24 (Embedding)    (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d_24 (Conv1D)          (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " max_pooling1d_24 (MaxPooli  (None, 19, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " flatten_24 (Flatten)        (None, 2432)              0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 128)               311424    \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1376842 (5.25 MB)\n",
            "Trainable params: 1376842 (5.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------\n",
            "Epochs: 20 - Batch Size: 32\n",
            "--------------------------\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.3094 - accuracy: 0.0000e+00 - val_loss: 2.2951 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.2921 - accuracy: 0.0000e+00 - val_loss: 2.2839 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2779 - accuracy: 0.0000e+00 - val_loss: 2.2726 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2649 - accuracy: 0.5000 - val_loss: 2.2622 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2524 - accuracy: 0.5000 - val_loss: 2.2522 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2406 - accuracy: 0.5000 - val_loss: 2.2412 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 2.2289 - accuracy: 0.5000 - val_loss: 2.2313 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.2177 - accuracy: 0.5000 - val_loss: 2.2225 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.2070 - accuracy: 0.5000 - val_loss: 2.2138 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.1971 - accuracy: 0.5000 - val_loss: 2.2045 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.1877 - accuracy: 0.5000 - val_loss: 2.1944 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.1781 - accuracy: 0.5000 - val_loss: 2.1846 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.1682 - accuracy: 0.5000 - val_loss: 2.1746 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.1578 - accuracy: 0.5000 - val_loss: 2.1638 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.1468 - accuracy: 0.5000 - val_loss: 2.1520 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.1358 - accuracy: 0.5000 - val_loss: 2.1415 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.1245 - accuracy: 0.5000 - val_loss: 2.1296 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.1130 - accuracy: 0.5000 - val_loss: 2.1178 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.1012 - accuracy: 0.5000 - val_loss: 2.1065 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.0892 - accuracy: 0.5000 - val_loss: 2.0941 - val_accuracy: 0.0000e+00\n",
            ">>>END<<<\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_25 (Embedding)    (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d_25 (Conv1D)          (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " max_pooling1d_25 (MaxPooli  (None, 19, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " flatten_25 (Flatten)        (None, 2432)              0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 128)               311424    \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1376842 (5.25 MB)\n",
            "Trainable params: 1376842 (5.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------\n",
            "Epochs: 20 - Batch Size: 64\n",
            "--------------------------\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.2747 - accuracy: 0.5000 - val_loss: 2.2567 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 2.2544 - accuracy: 0.5000 - val_loss: 2.2393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.2365 - accuracy: 0.5000 - val_loss: 2.2238 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 2.2204 - accuracy: 0.5000 - val_loss: 2.2082 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 2.2052 - accuracy: 1.0000 - val_loss: 2.1919 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 2.1900 - accuracy: 1.0000 - val_loss: 2.1755 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 2.1747 - accuracy: 0.5000 - val_loss: 2.1585 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 2.1587 - accuracy: 0.5000 - val_loss: 2.1418 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 2.1427 - accuracy: 0.5000 - val_loss: 2.1252 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 2.1264 - accuracy: 0.5000 - val_loss: 2.1087 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 2.1100 - accuracy: 0.5000 - val_loss: 2.0916 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 2.0930 - accuracy: 0.5000 - val_loss: 2.0744 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 2.0761 - accuracy: 0.5000 - val_loss: 2.0566 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.0589 - accuracy: 0.5000 - val_loss: 2.0383 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.0412 - accuracy: 0.5000 - val_loss: 2.0198 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.0227 - accuracy: 0.5000 - val_loss: 2.0006 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 2.0036 - accuracy: 0.5000 - val_loss: 1.9805 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 1.9836 - accuracy: 0.5000 - val_loss: 1.9582 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.9630 - accuracy: 0.5000 - val_loss: 1.9364 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 1.9414 - accuracy: 0.5000 - val_loss: 1.9131 - val_accuracy: 1.0000\n",
            ">>>END<<<\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_26 (Embedding)    (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d_26 (Conv1D)          (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " max_pooling1d_26 (MaxPooli  (None, 19, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " flatten_26 (Flatten)        (None, 2432)              0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 128)               311424    \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1376842 (5.25 MB)\n",
            "Trainable params: 1376842 (5.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------\n",
            "Epochs: 20 - Batch Size: 128\n",
            "--------------------------\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.2932 - accuracy: 0.0000e+00 - val_loss: 2.2588 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 2.2730 - accuracy: 0.5000 - val_loss: 2.2398 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2541 - accuracy: 0.5000 - val_loss: 2.2215 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2363 - accuracy: 0.5000 - val_loss: 2.2036 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 2.2187 - accuracy: 0.5000 - val_loss: 2.1858 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.2016 - accuracy: 0.5000 - val_loss: 2.1682 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.1843 - accuracy: 0.5000 - val_loss: 2.1512 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.1671 - accuracy: 0.5000 - val_loss: 2.1340 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.1500 - accuracy: 0.5000 - val_loss: 2.1171 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.1330 - accuracy: 0.5000 - val_loss: 2.0997 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.1153 - accuracy: 0.5000 - val_loss: 2.0797 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.0967 - accuracy: 0.5000 - val_loss: 2.0610 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.0774 - accuracy: 0.5000 - val_loss: 2.0405 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 2.0571 - accuracy: 0.5000 - val_loss: 2.0199 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.0358 - accuracy: 0.5000 - val_loss: 1.9984 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.0142 - accuracy: 0.5000 - val_loss: 1.9751 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 1.9918 - accuracy: 0.5000 - val_loss: 1.9522 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 1.9681 - accuracy: 0.5000 - val_loss: 1.9268 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 1.9439 - accuracy: 0.5000 - val_loss: 1.8994 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 1.9182 - accuracy: 0.5000 - val_loss: 1.8730 - val_accuracy: 1.0000\n",
            ">>>END<<<\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_27 (Embedding)    (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d_27 (Conv1D)          (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " max_pooling1d_27 (MaxPooli  (None, 19, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " flatten_27 (Flatten)        (None, 2432)              0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 128)               311424    \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1376842 (5.25 MB)\n",
            "Trainable params: 1376842 (5.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------\n",
            "Epochs: 30 - Batch Size: 32\n",
            "--------------------------\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.3389 - accuracy: 0.0000e+00 - val_loss: 2.3193 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.3168 - accuracy: 0.0000e+00 - val_loss: 2.2993 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 2.2964 - accuracy: 0.0000e+00 - val_loss: 2.2816 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2773 - accuracy: 0.5000 - val_loss: 2.2656 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.2599 - accuracy: 1.0000 - val_loss: 2.2502 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 2.2449 - accuracy: 1.0000 - val_loss: 2.2376 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.2308 - accuracy: 1.0000 - val_loss: 2.2245 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 2.2173 - accuracy: 1.0000 - val_loss: 2.2123 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 2.2055 - accuracy: 0.5000 - val_loss: 2.2006 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.1943 - accuracy: 0.5000 - val_loss: 2.1891 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 2.1831 - accuracy: 0.5000 - val_loss: 2.1785 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.1721 - accuracy: 0.5000 - val_loss: 2.1680 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.1614 - accuracy: 0.5000 - val_loss: 2.1575 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.1505 - accuracy: 0.5000 - val_loss: 2.1462 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.1392 - accuracy: 0.5000 - val_loss: 2.1347 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.1278 - accuracy: 0.5000 - val_loss: 2.1247 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.1161 - accuracy: 1.0000 - val_loss: 2.1123 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.1040 - accuracy: 1.0000 - val_loss: 2.0994 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 2.0912 - accuracy: 1.0000 - val_loss: 2.0878 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 2.0779 - accuracy: 1.0000 - val_loss: 2.0746 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.0647 - accuracy: 1.0000 - val_loss: 2.0610 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.0507 - accuracy: 1.0000 - val_loss: 2.0483 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 2.0366 - accuracy: 1.0000 - val_loss: 2.0337 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 2.0223 - accuracy: 1.0000 - val_loss: 2.0174 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 2.0068 - accuracy: 1.0000 - val_loss: 2.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 1.9916 - accuracy: 1.0000 - val_loss: 1.9864 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.9748 - accuracy: 1.0000 - val_loss: 1.9695 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.9577 - accuracy: 1.0000 - val_loss: 1.9536 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 1.9403 - accuracy: 1.0000 - val_loss: 1.9343 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1.9218 - accuracy: 1.0000 - val_loss: 1.9156 - val_accuracy: 1.0000\n",
            ">>>END<<<\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_28 (Embedding)    (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d_28 (Conv1D)          (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " max_pooling1d_28 (MaxPooli  (None, 19, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " flatten_28 (Flatten)        (None, 2432)              0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 128)               311424    \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1376842 (5.25 MB)\n",
            "Trainable params: 1376842 (5.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------\n",
            "Epochs: 30 - Batch Size: 64\n",
            "--------------------------\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 2.3023 - accuracy: 0.0000e+00 - val_loss: 2.2880 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2865 - accuracy: 0.5000 - val_loss: 2.2728 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 2.2716 - accuracy: 0.5000 - val_loss: 2.2585 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2578 - accuracy: 1.0000 - val_loss: 2.2444 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2445 - accuracy: 1.0000 - val_loss: 2.2322 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.2318 - accuracy: 1.0000 - val_loss: 2.2197 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.2199 - accuracy: 1.0000 - val_loss: 2.2086 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.2080 - accuracy: 1.0000 - val_loss: 2.1964 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.1962 - accuracy: 1.0000 - val_loss: 2.1845 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.1842 - accuracy: 1.0000 - val_loss: 2.1729 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.1725 - accuracy: 1.0000 - val_loss: 2.1602 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.1604 - accuracy: 1.0000 - val_loss: 2.1488 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.1484 - accuracy: 1.0000 - val_loss: 2.1366 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.1358 - accuracy: 1.0000 - val_loss: 2.1238 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.1230 - accuracy: 0.5000 - val_loss: 2.1098 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.1092 - accuracy: 0.5000 - val_loss: 2.0954 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.0948 - accuracy: 0.5000 - val_loss: 2.0804 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.0801 - accuracy: 0.5000 - val_loss: 2.0644 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.0652 - accuracy: 0.5000 - val_loss: 2.0492 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.0499 - accuracy: 0.5000 - val_loss: 2.0338 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.0338 - accuracy: 0.5000 - val_loss: 2.0160 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.0172 - accuracy: 0.5000 - val_loss: 1.9990 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.0004 - accuracy: 0.5000 - val_loss: 1.9791 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1.9826 - accuracy: 0.5000 - val_loss: 1.9612 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 1.9642 - accuracy: 0.5000 - val_loss: 1.9419 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 1.9453 - accuracy: 0.5000 - val_loss: 1.9204 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.9256 - accuracy: 0.5000 - val_loss: 1.8983 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.9049 - accuracy: 0.5000 - val_loss: 1.8758 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1.8837 - accuracy: 0.5000 - val_loss: 1.8520 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1.8611 - accuracy: 0.5000 - val_loss: 1.8270 - val_accuracy: 1.0000\n",
            ">>>END<<<\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_29 (Embedding)    (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d_29 (Conv1D)          (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " max_pooling1d_29 (MaxPooli  (None, 19, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " flatten_29 (Flatten)        (None, 2432)              0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 128)               311424    \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1376842 (5.25 MB)\n",
            "Trainable params: 1376842 (5.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------\n",
            "Epochs: 30 - Batch Size: 128\n",
            "--------------------------\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 2.3073 - accuracy: 0.0000e+00 - val_loss: 2.2792 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2878 - accuracy: 0.0000e+00 - val_loss: 2.2627 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2700 - accuracy: 0.0000e+00 - val_loss: 2.2468 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2533 - accuracy: 0.5000 - val_loss: 2.2293 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2374 - accuracy: 0.5000 - val_loss: 2.2159 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2231 - accuracy: 0.5000 - val_loss: 2.2016 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2088 - accuracy: 0.5000 - val_loss: 2.1886 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.1942 - accuracy: 0.5000 - val_loss: 2.1747 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.1796 - accuracy: 0.5000 - val_loss: 2.1605 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.1651 - accuracy: 0.5000 - val_loss: 2.1462 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.1504 - accuracy: 0.5000 - val_loss: 2.1314 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.1357 - accuracy: 0.5000 - val_loss: 2.1160 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.1203 - accuracy: 0.5000 - val_loss: 2.1001 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.1047 - accuracy: 0.5000 - val_loss: 2.0848 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.0887 - accuracy: 0.5000 - val_loss: 2.0685 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.0726 - accuracy: 0.5000 - val_loss: 2.0521 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.0558 - accuracy: 0.5000 - val_loss: 2.0344 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 2.0384 - accuracy: 0.5000 - val_loss: 2.0169 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.0206 - accuracy: 0.5000 - val_loss: 1.9975 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.0018 - accuracy: 0.5000 - val_loss: 1.9781 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1.9826 - accuracy: 0.5000 - val_loss: 1.9580 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.9625 - accuracy: 0.5000 - val_loss: 1.9368 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1.9416 - accuracy: 0.5000 - val_loss: 1.9150 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1.9199 - accuracy: 0.5000 - val_loss: 1.8920 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.8969 - accuracy: 0.5000 - val_loss: 1.8671 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.8733 - accuracy: 0.5000 - val_loss: 1.8414 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.8486 - accuracy: 0.5000 - val_loss: 1.8159 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.8224 - accuracy: 0.5000 - val_loss: 1.7888 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.7951 - accuracy: 0.5000 - val_loss: 1.7590 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1.7671 - accuracy: 0.5000 - val_loss: 1.7301 - val_accuracy: 1.0000\n",
            ">>>END<<<\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ceWAfdes9RIP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}